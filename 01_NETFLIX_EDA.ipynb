{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGPY/UB1clrE+i4HqFxigs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaisja/projeto-aplicado-netflix/blob/main/01_NETFLIX_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fYQovhEsAZz"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "!pip -q install pyarrow fastparquet tqdm\n",
        "\n",
        "import os, gc, math, random, sys, textwrap, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
        "sns.set()\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/MACKENZIE/4S Ciência de Dados\"\n",
        "\n",
        "FILES = [\n",
        "    f\"{DATA_DIR}/combined_data_1.txt\",\n",
        "    f\"{DATA_DIR}/combined_data_2.txt\",\n",
        "    f\"{DATA_DIR}/combined_data_3.txt\",\n",
        "    f\"{DATA_DIR}/combined_data_4.txt\"\n",
        "]\n",
        "import os\n",
        "for f in FILES:\n",
        "    print(f, \"->\", os.path.exists(f))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVgQcnfXKUpw",
        "outputId": "9bb73794-b653-4fcf-fe29-9c140bb3d158"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/MACKENZIE/4S Ciência de Dados/combined_data_1.txt -> True\n",
            "/content/drive/MyDrive/MACKENZIE/4S Ciência de Dados/combined_data_2.txt -> True\n",
            "/content/drive/MyDrive/MACKENZIE/4S Ciência de Dados/combined_data_3.txt -> True\n",
            "/content/drive/MyDrive/MACKENZIE/4S Ciência de Dados/combined_data_4.txt -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pyarrow fastparquet tqdm\n",
        "\n",
        "import random, pandas as pd, numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "SAMPLE_RATE = 0.002\n",
        "MAX_ROWS_PER_FILE = None\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "CACHE_PARQUET = \"/content/netflix_all_sample.parquet\"\n",
        "CACHE_PARQUET_DRIVE = f\"{DATA_DIR}/netflix_all_sample.parquet\"\n",
        "\n",
        "def iter_netflix_file(path, sample_rate=1.0, max_rows=None, seed=SEED):\n",
        "    rng = random.Random(seed)\n",
        "    movie_id = None\n",
        "    out = 0\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.endswith(\":\"):\n",
        "                movie_id = int(line[:-1])\n",
        "                continue\n",
        "            try:\n",
        "                user_id, rating, dt = line.split(\",\")\n",
        "                if max_rows is not None and out >= max_rows:\n",
        "                    break\n",
        "                if sample_rate < 1.0 and rng.random() > sample_rate:\n",
        "                    continue\n",
        "                yield (int(user_id), movie_id, float(rating), dt)\n",
        "                out += 1\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "def load_all(files, sample_rate=SAMPLE_RATE, max_rows_per_file=MAX_ROWS_PER_FILE):\n",
        "    rows = []\n",
        "    for p in files:\n",
        "        print(\"Lendo:\", p)\n",
        "        for tup in tqdm(iter_netflix_file(p, sample_rate=sample_rate, max_rows=max_rows_per_file)):\n",
        "            rows.append(tup)\n",
        "    df = pd.DataFrame(rows, columns=[\"user_id\",\"movie_id\",\"rating\",\"date\"])\n",
        "    df[\"user_id\"]  = df[\"user_id\"].astype(\"int32\")\n",
        "    df[\"movie_id\"] = df[\"movie_id\"].astype(\"int32\")\n",
        "    df[\"rating\"]   = df[\"rating\"].astype(\"float32\")\n",
        "    df[\"date\"]     = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
        "    return df\n",
        "try:\n",
        "    import os\n",
        "    if os.path.exists(CACHE_PARQUET):\n",
        "        df = pd.read_parquet(CACHE_PARQUET)\n",
        "        print(\"Carregado do cache local:\", CACHE_PARQUET, df.shape)\n",
        "    elif os.path.exists(CACHE_PARQUET_DRIVE):\n",
        "        df = pd.read_parquet(CACHE_PARQUET_DRIVE)\n",
        "        print(\"Carregado do cache no Drive:\", CACHE_PARQUET_DRIVE, df.shape)\n",
        "    else:\n",
        "        df = load_all(FILES, sample_rate=SAMPLE_RATE, max_rows_per_file=MAX_ROWS_PER_FILE)\n",
        "        df.to_parquet(CACHE_PARQUET, index=False)\n",
        "        df.to_parquet(CACHE_PARQUET_DRIVE, index=False)\n",
        "        print(\"Amostra combinada salva em:\", CACHE_PARQUET, \"e\", CACHE_PARQUET_DRIVE, df.shape)\n",
        "except Exception as e:\n",
        "    print(\"Erro ao carregar/criar cache:\", e)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "2AsFmZSJKcmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_mb(df):\n",
        "    return df.memory_usage(deep=True).sum() / (1024**2)\n",
        "\n",
        "print(\"Shape:\", df.shape, \"| Memória (MB):\", round(memory_mb(df), 2))\n",
        "print(\"Período:\", df[\"date\"].min(), \"->\", df[\"date\"].max())\n",
        "print(\"\\nAusentes:\\n\", df.isna().sum())\n",
        "print(\"\\nDuplicatas exatas:\", df.duplicated().sum())\n"
      ],
      "metadata": {
        "id": "-ooFIA3MLG18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"rating\"].describe())\n",
        "\n",
        "# distribuição (tabela)\n",
        "rating_counts = df[\"rating\"].value_counts().sort_index()\n",
        "display(pd.DataFrame({\"rating\": rating_counts.index, \"count\": rating_counts.values,\n",
        "                      \"share\": (rating_counts/len(df)).values}))\n",
        "\n",
        "# gráfico\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,4))\n",
        "df[\"rating\"].value_counts().sort_index().plot(kind=\"bar\")\n",
        "plt.title(\"Distribuição de notas\")\n",
        "plt.xlabel(\"Nota\"); plt.ylabel(\"Contagem\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MustmAn0LILd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_activity = df.groupby(\"user_id\", as_index=False).size().rename(columns={\"size\":\"n_ratings_user\"})\n",
        "item_pop     = df.groupby(\"movie_id\", as_index=False).size().rename(columns={\"size\":\"n_ratings_item\"})\n",
        "\n",
        "print(\"Usuários únicos:\", user_activity.shape[0], \"| Itens únicos:\", item_pop.shape[0])\n",
        "display(user_activity[\"n_ratings_user\"].describe())\n",
        "display(item_pop[\"n_ratings_item\"].describe())\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(user_activity[\"n_ratings_user\"], bins=60)\n",
        "plt.yscale(\"log\"); plt.title(\"Avaliações por usuário (log-y)\")\n",
        "plt.xlabel(\"# avaliações por usuário\"); plt.ylabel(\"freq (log)\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(item_pop[\"n_ratings_item\"], bins=60)\n",
        "plt.yscale(\"log\"); plt.title(\"Avaliações por item (log-y)\")\n",
        "plt.xlabel(\"# avaliações por item\"); plt.ylabel(\"freq (log)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PWmgCOAcLKkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_obs = len(df)\n",
        "n_users = user_activity.shape[0]\n",
        "n_items = item_pop.shape[0]\n",
        "density = n_obs / (n_users * n_items)\n",
        "print(f\"Interações: {n_obs:,} | Usuários: {n_users:,} | Itens: {n_items:,}\")\n",
        "print(f\"Densidade (sparsidade): {density:.8f} -> matriz extremamente esparsa\")\n"
      ],
      "metadata": {
        "id": "GNABeWTtLPd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_items = (df.groupby(\"movie_id\")[\"rating\"]\n",
        "               .agg(n_ratings=\"count\", mean_rating=\"mean\")\n",
        "               .sort_values(\"n_ratings\", ascending=False)\n",
        "               .head(15))\n",
        "display(top_items)\n",
        "\n",
        "top_users = (df.groupby(\"user_id\")[\"rating\"]\n",
        "               .agg(n_ratings=\"count\", mean_rating=\"mean\")\n",
        "               .sort_values(\"n_ratings\", ascending=False)\n",
        "               .head(15))\n",
        "display(top_users)\n",
        "\n",
        "MIN_RATINGS = 200\n",
        "best_items = (df.groupby(\"movie_id\")[\"rating\"]\n",
        "                .agg(n_ratings=\"count\", mean_rating=\"mean\")\n",
        "                .query(\"n_ratings >= @MIN_RATINGS\")\n",
        "                .sort_values(\"mean_rating\", ascending=False)\n",
        "                .head(15))\n",
        "display(best_items)\n"
      ],
      "metadata": {
        "id": "ionrdMldLTKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "df[\"month\"] = df[\"date\"].values.astype(\"datetime64[M]\")\n",
        "\n",
        "ts_month = (df.groupby(\"month\", as_index=True)\n",
        "              .size()\n",
        "              .rename(\"n_ratings\")\n",
        "              .sort_index())\n",
        "\n",
        "last_month = ts_month.index.max()\n",
        "in_last = (df[\"month\"] == last_month)\n",
        "n_unique_days = df.loc[in_last, \"date\"].dt.day.nunique()\n",
        "if n_unique_days < 25:\n",
        "    ts_month = ts_month.iloc[:-1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,4))\n",
        "ax.plot(ts_month.index, ts_month.values, linewidth=1.5, label=\"Mensal\")\n",
        "\n",
        "roll3 = ts_month.rolling(window=3, center=True).mean()\n",
        "ax.plot(roll3.index, roll3.values, linewidth=2.0, label=\"Média móvel (3M)\")\n",
        "\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "ax.xaxis.set_minor_locator(mdates.MonthLocator(bymonth=[1,4,7,10]))\n",
        "\n",
        "ax.set_title(\"Avaliações por mês\")\n",
        "ax.set_xlabel(\"Ano\")\n",
        "ax.set_ylabel(\"# avaliações\")\n",
        "ax.grid(True, which=\"both\", alpha=0.25)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df[\"weekday\"] = df[\"date\"].dt.weekday\n",
        "wk = df[\"weekday\"].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(wk.index, wk.values)\n",
        "plt.title(\"Avaliações por dia da semana\")\n",
        "plt.xlabel(\"Dia (0=Seg … 6=Dom)\")\n",
        "plt.ylabel(\"Contagem\")\n",
        "plt.grid(True, axis=\"y\", alpha=0.25)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AvC6H86AL5gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = (df.groupby(\"movie_id\")[\"rating\"]\n",
        "         .agg(n_ratings=\"count\", mean_rating=\"mean\"))\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(tmp[\"n_ratings\"], tmp[\"mean_rating\"], s=8, alpha=0.5)\n",
        "plt.xscale(\"log\")\n",
        "plt.title(\"Média x #avaliações por item (log-x)\")\n",
        "plt.xlabel(\"# avaliações (item)\"); plt.ylabel(\"média de nota\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-Of4b73AME_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_cold = (user_activity[\"n_ratings_user\"] <= 5).mean()\n",
        "i_cold = (item_pop[\"n_ratings_item\"] <= 5).mean()\n",
        "print(f\"% usuários com <=5 avaliações: {100*u_cold:.2f}%\")\n",
        "print(f\"% itens com <=5 avaliações:   {100*i_cold:.2f}%\")\n"
      ],
      "metadata": {
        "id": "qe5Rlly1MH6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before = len(df)\n",
        "df = df.dropna(subset=[\"date\"])\n",
        "df = df.sort_values([\"user_id\",\"movie_id\",\"date\"])\n",
        "\n",
        "dup_count = df.duplicated(subset=[\"user_id\",\"movie_id\",\"date\",\"rating\"]).sum()\n",
        "df = df[~df.duplicated(subset=[\"user_id\",\"movie_id\",\"date\",\"rating\"])].reset_index(drop=True)\n",
        "print(\"Removidas (NaT + duplicatas):\", before - len(df), \"| duplicatas:\", dup_count)\n",
        "\n",
        "MIN_U, MIN_I = 5, 5\n",
        "u_keep = df[\"user_id\"].map(df[\"user_id\"].value_counts()) >= MIN_U\n",
        "i_keep = df[\"movie_id\"].map(df[\"movie_id\"].value_counts()) >= MIN_I\n",
        "df_small = df[u_keep & i_keep].reset_index(drop=True)\n",
        "\n",
        "print(\"Shape total:\", before, \"-> após limpeza:\", df.shape, \"-> POC:\", df_small.shape)\n",
        "\n",
        "OUT_PARQUET = \"/content/netflix_poc_clean.parquet\"\n",
        "OUT_PARQUET_DRIVE = f\"{DATA_DIR}/netflix_poc_clean.parquet\"\n",
        "df_small.to_parquet(OUT_PARQUET, index=False)\n",
        "df_small.to_parquet(OUT_PARQUET_DRIVE, index=False)\n",
        "print(\"POC salva em:\", OUT_PARQUET, \"e\", OUT_PARQUET_DRIVE)\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "BMI9lHqrMKro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df_small.sort_values([\"user_id\",\"date\"])\n",
        "last_idx = df_small.groupby(\"user_id\").tail(1).index\n",
        "val = df_small.loc[last_idx]\n",
        "train = df_small.drop(last_idx)\n",
        "\n",
        "print(\"Train:\", train.shape, \"| Val:\", val.shape)\n",
        "print(\"Período Train:\", train[\"date\"].min(), \"->\", train[\"date\"].max())\n",
        "print(\"Período Val:\",   val[\"date\"].min(),   \"->\", val[\"date\"].max())\n"
      ],
      "metadata": {
        "id": "coA9fyD_MNhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar dependências\n",
        "!pip -q install scikit-surprise pyarrow fastparquet\n",
        "\n",
        "# 2. Corrigir numpy\n",
        "!pip uninstall -y numpy\n",
        "!pip install \"numpy<2\"\n",
        "\n",
        "# 3. Reiniciar runtime automaticamente\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "id": "lLUt4W6VOdv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "tQaViex0OdoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy, pandas\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "\n",
        "from surprise import Dataset, Reader, SVD\n",
        "print(\"Surprise import OK!\")\n"
      ],
      "metadata": {
        "id": "eSEL1ldWO0uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# POC: Sistema de Recomendação (SVD - filtragem colaborativa)\n",
        "\n",
        "# Carregar bibliotecas\n",
        "import os, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n",
        "# 1) Carregar parquet (base preparada na EDA)\n",
        "PARQUET_PATH = \"/content/netflix_poc_clean.parquet\"\n",
        "assert os.path.exists(PARQUET_PATH), \"Preciso rodar a EDA antes para gerar este arquivo.\"\n",
        "\n",
        "df = pd.read_parquet(PARQUET_PATH)[[\"user_id\",\"movie_id\",\"rating\",\"date\"]]\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "# 2) Split leave-one-out por usuário\n",
        "#    -> última avaliação de cada usuário fica para validação\n",
        "\n",
        "df = df.sort_values([\"user_id\",\"date\"])\n",
        "val_idx = df.groupby(\"user_id\").tail(1).index\n",
        "val_df = df.loc[val_idx].copy()\n",
        "train_df = df.drop(val_idx).copy()\n",
        "\n",
        "print(\"Train:\", train_df.shape, \"| Val:\", val_df.shape)\n",
        "\n",
        "# 3) Treino com SVD\n",
        "reader = Reader(rating_scale=(1,5))\n",
        "train_data = Dataset.load_from_df(train_df[[\"user_id\",\"movie_id\",\"rating\"]], reader)\n",
        "trainset = train_data.build_full_trainset()\n",
        "\n",
        "# parâmetros default já funcionam bem p/ POC\n",
        "svd = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
        "svd.fit(trainset)\n",
        "\n",
        "# 4) Avaliação na validação\n",
        "# predição de cada par (user, movie) da validação\n",
        "preds = [svd.predict(int(u), int(i)).est\n",
        "         for u,i in val_df[[\"user_id\",\"movie_id\"]].itertuples(index=False, name=None)]\n",
        "\n",
        "y_true = val_df[\"rating\"].astype(float).values\n",
        "y_hat  = np.array(preds)\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(y_true, y_hat))\n",
        "mae  = mean_absolute_error(y_true, y_hat)\n",
        "print(f\"SVD POC -> RMSE: {rmse:.4f} | MAE: {mae:.4f}\")\n",
        "\n",
        "# 5) Baseline simples (média global)\n",
        "#    -> só p/ mostrar que o modelo melhora algo\n",
        "global_mean = train_df[\"rating\"].mean()\n",
        "rmse_base = math.sqrt(mean_squared_error(y_true, np.full_like(y_true, global_mean)))\n",
        "mae_base  = mean_absolute_error(y_true, np.full_like(y_true, global_mean))\n",
        "\n",
        "print(f\"Baseline (média) -> RMSE: {rmse_base:.4f} | MAE: {mae_base:.4f}\")\n",
        "print(f\"Ganho vs baseline (ΔRMSE): {(rmse_base - rmse):.4f}\")\n",
        "\n",
        "# 6) Top-10 recomendações para um usuário qualquer (demonstração)\n",
        "user_example = int(train_df[\"user_id\"].iloc[0])  # pegar o primeiro só para testar\n",
        "seen = set(train_df.loc[train_df[\"user_id\"]==user_example, \"movie_id\"].unique())\n",
        "all_items = set(train_df[\"movie_id\"].unique())\n",
        "candidates = list(all_items - seen)\n",
        "\n",
        "# limitar a 5000 itens só para rodar rápido\n",
        "candidates = candidates[:5000]\n",
        "\n",
        "scores = [(iid, svd.predict(user_example, int(iid)).est) for iid in candidates]\n",
        "top10 = sorted(scores, key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "print(\"\\nTop-10 itens recomendados (movie_id, score) para o usuário\", user_example)\n",
        "for iid, s in top10:\n",
        "    print(iid, f\"{s:.3f}\")\n"
      ],
      "metadata": {
        "id": "nayFAqOoPLml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# valores vindos da POC\n",
        "rmse_svd, mae_svd = 1.0190, 0.8323\n",
        "rmse_base, mae_base = 1.0776, 0.9019\n",
        "\n",
        "metrics = [\"RMSE\", \"MAE\"]\n",
        "baseline_vals = [rmse_base, mae_base]\n",
        "svd_vals      = [rmse_svd, mae_svd]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,4))\n",
        "rects1 = ax.bar(x - width/2, baseline_vals, width, label=\"Baseline (média)\")\n",
        "rects2 = ax.bar(x + width/2, svd_vals,      width, label=\"SVD (POC)\")\n",
        "\n",
        "ax.set_title(\"Figura 7 – Comparação de erro: Baseline vs. SVD (POC)\")\n",
        "ax.set_ylabel(\"Valor da métrica\")\n",
        "ax.set_xticks(x, metrics)\n",
        "ax.legend()\n",
        "ax.grid(axis=\"y\", alpha=0.25)\n",
        "\n",
        "# mostrar valores acima das barras\n",
        "for rects in [rects1, rects2]:\n",
        "    for r in rects:\n",
        "        h = r.get_height()\n",
        "        ax.annotate(f\"{h:.4f}\", xy=(r.get_x()+r.get_width()/2, h),\n",
        "                    xytext=(0, 3), textcoords=\"offset points\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SA5JkA3iR0Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhE6GObbR0Sj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}